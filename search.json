[
  {
    "objectID": "contents/blog/2020-10-31-wapoR/index.html",
    "href": "contents/blog/2020-10-31-wapoR/index.html",
    "title": "R API to download FAO’s WaPOR datasets",
    "section": "",
    "text": "Screenshot of from the WaPOR website\n\nWhat is it about?\nThe WaPOR project by FAO offers some awesome remote sensing products concerned with water usage in agriculture on the African continent. A great variety of different products, among them net- and gross-biomass-water-productivity, evaporation, transpiration, and interception as well as biomass production, are provided at a spatial resolution ranging between 250 meters up-to 30 meters for selected agricultural regions.\nThere are already some Python packages out there that allow users to programmatically access the WaPOR data portal such as hkvwaporpy or IHEWAwapor. However, I was not able to find similar functionality for R users. So I just went on and wrote an experimental package in R, which can be used to download raster data.\n\n\nWhat can it do?\nTo install and use the package, you should utilize remotes functionality.\n\nif(!\"wapoR\" %in% installed.packages()[,1]){\n  remotes::install_github(\"goergen95/wapoR\")\n}\nlibrary(wapoR)\n\nFrom there, it is quite straightforward to query available collections. Note that there are other collections available for which, in principal, it should be possible to download the data in the same way. But this package was primarily intended to interact with the WaPOR collections.\n\ncols = wapor_collections()\ncols[rev(seq(1,nrow(cols),)),c(1:2)]\n\n            code\n28          WPOP\n27         WATER\n26       WAPOR_2\n25           RVF\n24        RSCROP\n23      RICCAR_2\n22        RICCAR\n21          RDMS\n20          NMME\n19 NATURAL_EARTH\n18          NASA\n17          GLW4\n16          GLW3\n15           GLW\n14        GLEAM3\n13   GISMGR_TEST\n12       GAEZ_V4\n11     GAEZ_2015\n10      FROM_GLC\n9        FAOSTAT\n8           DLMF\n7           CRTB\n6      CROPWATCH\n5         CHIRPS\n4            C3S\n3        C2ATLAS\n2           ASIS\n1       AQUAMAPS\n                                                                       caption\n28                                                            WorldPop project\n27                                                                  Water Data\n26                           FAO Water Productivity Open-access portal (WaPOR)\n25                                                           Rift Valley Fever\n24                     Crop Pest and Disease Monitoring and Forecasting System\n23                              Regional Arab Climate Change Assessment Report\n22                              Regional Arab Climate Change Assessment Report\n21                                          Regional Drought Monitoring System\n20                                  North American Multi-Model Ensemble (NMME)\n19                                                               Natural Earth\n18                        National Aeronautics and Space Administration (NASA)\n17                                 Gridded Livestock of the World (GLW4, 2015)\n16                                 Gridded Livestock of the World (GLW3, 2010)\n15                                              Gridded Livestock of the World\n14                    Global Livestock Environmental Assessment Model (GLEAM3)\n13                      FAO GIS MANAGER (GISMGR) - Test and training workspace\n12                                         Global Agro-Ecological Zones (2021)\n11                                         Global Agro-Ecological Zones (2015)\n10 Finer Resolution Observation and Monitoring of Global Land Cover (FROM-GLC)\n9                                           FAO Corporate Statistical Database\n8                                     Desert Locust Monitoring and Forecasting\n7                                                  Climate Risk Toolbox (CRTB)\n6                                                                    CropWatch\n5           Climate Hazard group InfraRed Precipitation with Stations (CHIRPS)\n4                                            Copernicus Climate Change Service\n3                                                         Climate Change ATLAS\n2                                              Agriculture Stress Index System\n1                             Global spatial database on water and agriculture\n\n\nI reversed the order of the collections vector so that you can see that there are two available WaPOR collections representing version 1 and 2, respectively. I would advise using the updated version 2 if you do not have other reasons to use the first version.\nWe can query the available products within a collection by using wapor_products together with the collection we wish to query.\n\nprods = wapor_products(collection = \"WAPOR_2\")\n\nprint(paste0(\"In total there are \", length(prods), \" available products in the WAPOR_2 collection.\"))\n\n[1] \"In total there are 285 available products in the WAPOR_2 collection.\"\n\nstr(prods[1])\n\nList of 1\n $ L1_GBWP_A:List of 2\n  ..$ product:'data.frame': 1 obs. of  3 variables:\n  .. ..$ code       : chr \"L1_GBWP_A\"\n  .. ..$ caption    : chr \"Gross Biomass Water Productivity\"\n  .. ..$ description: chr \"The annual Gross Biomass Water Productivity expresses the quantity of output (total biomass production) in rela\"| __truncated__\n  ..$ meta   :'data.frame': 1 obs. of  12 variables:\n  .. ..$ format                : chr \"Raster Dataset\"\n  .. ..$ unit                  : chr \"kg/m³ is the ratio of kg of dry matter per cubic meter of water transpired by vegetation in one hectare\"\n  .. ..$ dataType              : chr \"Int32 (32bit Integer)\"\n  .. ..$ conversionFactor      : chr \"the pixel value in the downloaded data must be multiplied by 0.001\"\n  .. ..$ noDataValue           : int -9999\n  .. ..$ spatialResolution     : chr \"250m (0.00223 degree)\"\n  .. ..$ spatialExtent         : chr \"Africa and Near East\"\n  .. ..$ spatialReferenceSystem: chr \"EPSG:4326 - WGS84 - Geographic Coordinate System (lat/long)\"\n  .. ..$ temporalResolution    : chr \"from January 2009 to present\"\n  .. ..$ temporalExtent        : chr \"Annual\"\n  .. ..$ nearRealTime          : chr \"New dekadal data layers are released approximately 5 days after the end of a dekad. A higher quality version of\"| __truncated__\n  .. ..$ methodology           : chr \"The calculation of gross biomass water productivity (GBWP) is as follows: GBWP = TBP/ETIa Where TBP is annual T\"| __truncated__\n\nnames(prods)[1:10]\n\n [1] \"L1_GBWP_A\" \"L1_NBWP_A\" \"L1_AETI_A\" \"L1_AETI_M\" \"L1_AETI_D\" \"L1_T_A\"   \n [7] \"L1_E_A\"    \"L1_I_A\"    \"L1_T_D\"    \"L1_E_D\"   \n\n\nThe total number of products is relatively high. The product names consist first of the level a respective product belongs to. Level 1 means this product belongs to the continental products covering the African continent at a spatial resolution of about 250 meters. Level 2 products show a resolution of 100 meters. However, they are only available for selected countries. Finally, level 3 data is available for only a few specific agricultural regions, but the spatial resolution is about 30 meters.\nThe second component in the product name specifies the variable. For example, GBWP stands for Gross Biomass Water Productivity or AETI for Actual Evapotranspiraton and Interception. You can check out the WaPOR catalog to see all available products, or you search through the product list as some metadata is also included in the above object.\nThe last component of a product name specifies its temporal resolution, where A stands for annual, M for monthly, D for decadal, and S for a seasonal temporal resolution.\nLet’s assume we decided to download some level 3 data for the Office du Niger agricultural region. First, let’s take a look at the available products:\n\nnames(prods)[grep(\"L3_ODN\", names(prods))]\n\n [1] \"L3_ODN_GBWP_S\"       \"L3_ODN_NBWP_S\"       \"L3_ODN_AETI_A\"      \n [4] \"L3_ODN_AETI_M\"       \"L3_ODN_AETI_D\"       \"L3_ODN_T_A\"         \n [7] \"L3_ODN_E_A\"          \"L3_ODN_I_A\"          \"L3_ODN_T_D\"         \n[10] \"L3_ODN_E_D\"          \"L3_ODN_I_D\"          \"L3_ODN_NPP_M\"       \n[13] \"L3_ODN_NPP_D\"        \"L3_ODN_TBP_S\"        \"L3_ODN_LCC_D\"       \n[16] \"L3_ODN_PHE_S\"        \"L3_ODN_QUAL_LCC_S\"   \"L3_ODN_QUAL_NDVI_D\" \n[19] \"L3_ODN_QUAL_NDVI_LT\"\n\n\nFor the sake of a quick example, let’s say we are interested in the actual evapotranspiration and interception for the year 2018. We can query some additional metadata about this product with the following command:\n\nmeta = wapor_metadata(collection = \"WAPOR_2\", product = \"L3_ODN_AETI_A\")\nstr(meta)\n\nList of 3\n $ info      :'data.frame': 1 obs. of  5 variables:\n  ..$ code      : chr \"WATER_MM\"\n  ..$ caption   : chr \"Amount of Water\"\n  ..$ unit      : chr \"mm\"\n  ..$ scale     : int 3\n  ..$ multiplier: num 0.1\n $ dimensions:'data.frame': 1 obs. of  3 variables:\n  ..$ code   : chr \"YEAR\"\n  ..$ caption: chr \"Year\"\n  ..$ type   : chr \"TIME\"\n $ meta      :'data.frame': 1 obs. of  12 variables:\n  ..$ format                : chr \"Raster Dataset\"\n  ..$ unit                  : chr \"mm\"\n  ..$ dataType              : chr \"Int32 (32bit Integer)\"\n  ..$ conversionFactor      : chr \"the pixel value in the downloaded data must be multiplied by 0.1\"\n  ..$ noDataValue           : int -9999\n  ..$ spatialResolution     : chr \"30m\"\n  ..$ spatialExtent         : chr \"Office du Niger, Mali\"\n  ..$ spatialReferenceSystem: chr \"EPSG:32630 - WGS 84 / UTM zone 30N\"\n  ..$ temporalResolution    : chr \"from January 2009 to present\"\n  ..$ temporalExtent        : chr \"Annual\"\n  ..$ nearRealTime          : chr \"New dekadal data layers are released approximately 5 days after the end of a dekad. A higher quality version of\"| __truncated__\n  ..$ methodology           : chr \"See ETIa by dekad for further information. The annual total is obtained by taking the ETIa in mm/day, multiplyi\"| __truncated__\n\n\nFrom the above, we already get a lot of useful information. For example, we see that the product is available between 2009 and the current year and is provided in a projected coordinate reference system. We also can see that the unit of the pixel values is in millimeters bit that the pixel value shall be multiplied with a scale factor of 0.1. This is essential information, and it should be checked for all WaPOR products since most of them were rescaled to reduce file size.\nMaybe the most important aspect of the above output for the next step, is the dimensions dataframe. Here we can see that the selected product only shows one dimension called “YEAR” which type is time. Other products might have further dimensions, such as “SEASON” which needs different specification in the download call.\n\nwapor_queryRaster(collection = \"WAPOR_2\",\n                  product = \"L3_ODN_AETI_A\",\n                  begin = \"2018-01-01\", # begin date is inclusive\n                  end = \"2019-01-01\", # end date is exclusive\n                  outdir = \".\",\n                  APIkey = Sys.getenv(\"WAPOR-KEY\")) \n\nLet’s take a glimpse at the data we just downloaded.\n\nlibrary(raster)\n\nLoading required package: sp\n\nfile = list.files(\".\", \"L3_ODN\", full.names = T)\nr = raster(file) * 0.1\nplot(r)\n\n\n\n\nWe very quickly downloaded some important data for an assessment of agricultural practices in ODN. This package’s download functionality can be used to download specific regions from Level 2 or 3 datasets by providing an sf object of an area of interest. Additionally, complete-time series can be downloaded by adapting the start and end date. Check out the README of the package for another example to download some data and leave an issue if you face any problems using this package."
  },
  {
    "objectID": "contents/blog/2020-05-10-bufr2tif/index.html",
    "href": "contents/blog/2020-05-10-bufr2tif/index.html",
    "title": "Translating EUMETSAT’s .bfr files to GTiff",
    "section": "",
    "text": "import numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\nimport pyresample as pr\nfrom pybufr_ecmwf.bufr import BUFRReader\nimport matplotlib.pyplot as plt\n\nThe BUFR format is a standardized format defined by the World Meteorological Organization (WMO). It stands for Binary Universal Form for the Representation of meteorological data. It is a self-describing format, shipping data together with metadata to be used by end-users. Within a .bfr file, we find several messages, each of them having a specific number of entries. We will use the functionality of the pybufr_ecmwf library to read in the data.\n\nfile = \"MSG2-SEVI-MSGRIIE-0101-0101-20160526000000.000000000Z-20160526000602-1403456.bfr\"\n# read the file\nbufr = BUFRReader(file, warn_about_bufr_size = False, expand_flags = False)\n# display number of messages\nprint(\"Number of messages: \"+ str(bufr.num_msgs))\n\n# initiate list with parameter names\nnames_units = []\nfor m, msg in enumerate(bufr):\n names_units.append(msg.get_names_and_units())\n\n# show parameter names and units\nprint('\\n'.join(map(str, names_units[0][0])))\n# close file\nbufr.close()\n\nNumber of messages: 90\n\n\nSATELLITE IDENTIFIER\nIDENTIFICATION OF ORIGINATING/GENERATING CENTRE (SEE NOTE 10)\nSATELLITE CLASSIFICATION\nSEGMENT SIZE AT NADIR IN X DIRECTION\nSEGMENT SIZE AT NADIR IN Y DIRECTION\nYEAR\nMONTH\nDAY\nHOUR\nMINUTE\nSECOND\nROW NUMBER\nCOLUMN NUMBER\nLATITUDE (HIGH ACCURACY)\nLONGITUDE (HIGH ACCURACY)\nSATELLITE ZENITH ANGLE\nK INDEX\nKO INDEX\nPARCEL LIFTED INDEX (TO 500 HPA)\nMAXIMUM BUOYANCY\nPRECIPITABLE WATER\nPER CENT CONFIDENCE\nPRESSURE\nPRESSURE\nPRECIPITABLE WATER\nPRESSURE\nPRESSURE\nPRECIPITABLE WATER\nPRESSURE\nPRESSURE\nPRECIPITABLE WATER\n\n\nBased on the above output, we can decide which parameters we are interested in and which metadata we will need. Say we are only interested in the parameter K Index. We can see that the index for this dataset is 16. Also, since we are interested in writing a .tiff as output, the datasets of latitude and longitude will be of interest to us (index 13 and 14, respectively). Note that we are reopening the file once again to start from the very first message.\n\n# initiate arrays\nlats = np.zeros([0])\nlons = np.zeros([0])\nvals = np.zeros([0])\n# reopening the file\nbufr = BUFRReader(file, warn_about_bufr_size = False, expand_flags = False)\n\n# loop through the messages and sub-entries\nfor msg in bufr:\n for subs in msg:\n  data = subs.data\n  lats = np.append(lats, data[:,13])\n  lons = np.append(lons, data[:,14])\n  vals = np.append(vals, data[:,20])\n# don't forget to close the file\nbufr.close()\nvals = np.where(vals == np.max(vals), -9999, vals)\n\nWith this loop, we obtained all the necessary data to create a .tiff file. We have got the values we are interested in and the geographic information of each location’s latitude and longitude data. We can now use the pyresample library to resample our data to a location of interest. Let’s say we are interested in a study area roughly having the extent of France. We can resample to this area by declaring an area definition first.\n\n# define some general properties of our projection\narea_id = \"France\"\ndescription = \"Custom Geographical CRS of France\"\nproj_id = \"France WGS84 geographical\"\nproj_dict = {\"proj\": \"longlat\", \"ellps\":\"WGS84\", \"datum\": \"WGS84\"}\n# define the area's extent in degrees and desired resolution\nllx = -4.9\nlly = 42.2\nurx = 8.2\nury = 51.2\nres = 0.015 # in degrees\nwidth = int((urx - llx) / res)\nheight = int((ury - lly) / res)\narea_extent = (llx,lly,urx,ury)\narea_def = pr.geometry.AreaDefinition(area_id, proj_id, description, proj_dict, width, height, area_extent)\nprint(area_def)\n\nArea ID: France\nDescription: France WGS84 geographical\nProjection ID: Custom Geographical CRS of France\nProjection: {'datum': 'WGS84', 'no_defs': 'None', 'proj': 'longlat', 'type': 'crs'}\nNumber of columns: 873\nNumber of rows: 600\nArea extent: (-4.9, 42.2, 8.2, 51.2)\n\n\n/home/darius/Desktop/website/new/py-env/lib/python3.10/site-packages/pyproj/crs/crs.py:1282: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n  proj = self._crs.to_proj4(version=version)\n\n\nWith this area definition, we can resample our data using the nearest neighbor algorithm and use our defined variables about the location to create a .tiff file as output.\n\nswath_def = pr.geometry.SwathDefinition(lons = lons, lats = lats)\nres_data = pr.kd_tree.resample_nearest(swath_def, vals, area_def,\nradius_of_influence=16000,epsilon=0.5,fill_value=False)\n\n# create tif output\nfilename = \"bufr2tif.tif\"\n# number of rows and cols\nrows = res_data.shape[0]\ncols = res_data.shape[1]\n# pixel size\npixelWidth = (area_def.area_extent[2] - area_def.area_extent[0]) / cols\npixelHeight = (area_def.area_extent[1] - area_def.area_extent[3]) / rows\n# pixel of origin\noriginX = area_def.area_extent[0]\noriginY = area_def.area_extent[3]\n# driver\ndriver = gdal.GetDriverByName(\"GTiff\")\n# create file \noutRaster = driver.Create(filename, cols, rows, 1, gdal.GDT_Float32)\n# set resoultion and origin\noutRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n# create one band\noutband = outRaster.GetRasterBand(1)\n# Float_64 no data value (or customize)\noutband.SetNoDataValue(-9999)\n# write the resampled data to file\noutband.WriteArray(np.array(res_data))\n# create a spatial reference system\noutRasterSRS = osr.SpatialReference()\noutRasterSRS.ImportFromEPSG(4326)\n# write SRS to file\noutRaster.SetProjection(outRasterSRS.ExportToWkt())\n# clean up\noutband.FlushCache()\noutband = None\noutRaster = None\n\n\nNow we can read in the newly created file and look at a simple plot to visualize our result. Note that, in the background, I am using R to generate this plot quickly.\n\nfile = \"bufr2tif.tif\"\nds = gdal.Open(file)\nband = ds.GetRasterBand(1)\ndata = band.ReadAsArray()\ndata = np.where(data == -9999., np.NaN, data)\nplt.imshow(data)\n\n<matplotlib.image.AxesImage at 0x7f4afc87fb80>"
  },
  {
    "objectID": "contents/blog/2020-06-14-nat2tif/index.html",
    "href": "contents/blog/2020-06-14-nat2tif/index.html",
    "title": "Translating EUMETSAT’s .nat files to GTiff",
    "section": "",
    "text": "import numpy as np\nfrom osgeo import gdal\nfrom osgeo import osr\nimport os\nimport pyresample as pr\nfrom satpy import Scene\nimport matplotlib.pyplot as plt\n\nAs opposed to BUFR files, reading .nat files is quite straightforward. All we need to do is handing the right reader to the satpy Scene function. We can then take a look at the available datasets.\n\nfile = \"MSG1-SEVI-MSG15-0100-NA-20160531090417.660000000Z-20160531090437-1405098.nat\"\n# define reader\nreader = \"seviri_l1b_native\"\n# read the file\nscn = Scene(filenames = {reader:[file]})\n# extract data set names\ndataset_names = scn.all_dataset_names()\n# print available datasets\nprint('\\n'.join(map(str, dataset_names)))\n\nHRV\nIR_016\nIR_039\nIR_087\nIR_097\nIR_108\nIR_120\nIR_134\nVIS006\nVIS008\nWV_062\nWV_073\n\n\nThe MSG data is provided as Full Disk, meaning that roughly the complete North-South extent of the globe from the Atlantic to the Indian Ocean is present in each file. For most applications and research questions, it is not necessary to process an extent that large. This is why as an example, we are going to resample the data to the extent of Spain. For this, we are using functionality from the pyresample library, which allows users to create customized area definitions.\n\n# create some information on the reference system\narea_id = \"Spain\"\ndescription = \"Geographical Coordinate System clipped on Spain\"\nproj_id = \"Spain\"\n# specifing some parameters of the projection\nproj_dict = {\"proj\": \"longlat\", \"ellps\": \"WGS84\", \"datum\": \"WGS84\"}\n# calculate the width and height of the aoi in pixels\nllx = -9.5 # lower left x coordinate in degrees\nlly = 35.9 # lower left y coordinate in degrees\nurx = 3.3 # upper right x coordinate in degrees\nury = 43.8 # upper right y coordinate in degrees\nresolution = 0.005 # target resolution in degrees\n# calculating the number of pixels\nwidth = int((urx - llx) / resolution)\nheight = int((ury - lly) / resolution)\narea_extent = (llx,lly,urx,ury)\n# defining the area\narea_def = pr.geometry.AreaDefinition(area_id, proj_id, description, proj_dict, width, height, area_extent)\nprint(area_def)\n\nArea ID: Spain\nDescription: Spain\nProjection ID: Geographical Coordinate System clipped on Spain\nProjection: {'datum': 'WGS84', 'no_defs': 'None', 'proj': 'longlat', 'type': 'crs'}\nNumber of columns: 2560\nNumber of rows: 1579\nArea extent: (-9.5, 35.9, 3.3, 43.8)\n\n\n/home/darius/Desktop/website/new/py-env/lib/python3.10/site-packages/pyproj/crs/crs.py:1282: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n  proj = self._crs.to_proj4(version=version)\n\n\nWe will show here how to proceed when we want to extract more than one specific data set. We can either apply a for loop over the desired datasets we need or write a general function that can extract the data for any specified variable. Here we are going forward with the latter approach because a function is more reusable than a simple script.\n\ndef nat2tif(file, calibration, area_def, dataset, reader, outdir, label, dtype, radius, epsilon, nodata):\n  # open the file\n  scn = Scene(filenames = {reader: [file]})\n  # let us check that the specified data set is actually available\n  scn_names = scn.all_dataset_names()\n  # raise exception if dataset is not present in available names\n  if dataset not in scn_names:\n    raise Exception(\"Specified dataset is not available.\")\n  # we need to load the data, different calibration can be chosen\n  scn.load([dataset], calibration=calibration)\n  # let us extract the longitude and latitude data\n  lons, lats = scn[dataset].area.get_lonlats()\n  # now we can apply a swath definition for our output raster\n  swath_def = pr.geometry.SwathDefinition(lons=lons, lats=lats)\n  # and finally we also extract the data\n  values = scn[dataset].values\n  # we will now change the datatype of the arrays\n  # depending on the present data this can be changed\n  lons = lons.astype(dtype)\n  lats = lats.astype(dtype)\n  values = values.astype(dtype)\n  # now we can already resample our data to the area of interest\n  values = pr.kd_tree.resample_nearest(swath_def, values,\n                                             area_def,\n                                             radius_of_influence=radius, # in meters\n                                             epsilon=epsilon,\n                                             fill_value=False)\n  # we are going to check if the outdir exists and create it if it doesnt\n  if not os.path.exists(outdir):\n   os.makedirs(outdir)\n  # let us join our filename based on the input file's basename                                           \n  outname = os.path.join(outdir, os.path.basename(file)[:-4] + \"_\" + str(label) + \".tif\")\n  # now we define some metadata for our raster file\n  cols = values.shape[1]\n  rows = values.shape[0]\n  pixelWidth = (area_def.area_extent[2] - area_def.area_extent[0]) / cols\n  pixelHeight = (area_def.area_extent[1] - area_def.area_extent[3]) / rows\n  originX = area_def.area_extent[0]\n  originY = area_def.area_extent[3] \n  # here we actually create the file\n  driver = gdal.GetDriverByName(\"GTiff\")\n  outRaster = driver.Create(outname, cols, rows, 1)\n  # writing the metadata\n  outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n  # creating a new band and writting the data\n  outband = outRaster.GetRasterBand(1)\n  outband.SetNoDataValue(nodata) #specified no data value by user\n  outband.WriteArray(np.array(values)) # writting the values\n  outRasterSRS = osr.SpatialReference() # create CRS instance\n  outRasterSRS.ImportFromEPSG(4326) # get info for EPSG 4326\n  outRaster.SetProjection(outRasterSRS.ExportToWkt()) # set CRS as WKT\n  # clean up\n  outband.FlushCache()\n  outband = None\n  outRaster = None\n\nNow we can apply this function to our input file and extract any available dataset. Note that some of the input variables need further explanation. The very first option which might not be self-evident is calibration. With this option we can tell satpy to pre-calibrate the data, for example, to reflectance in contrast to radiances. The option label appends the value of label to the ouput filename. With the dtype option, we can specifically choose which datatype is used for the output file. Accordingly, we should adopt the value for nodata, which flags no data values in the output file. The options radius and epsilon are options of the nearest neighbor resampling routine and can be specified to the user needs (see here for more information).\n\nnat2tif(file = file, \n        calibration = \"radiance\",  \n        area_def = area_def,  \n        dataset = \"HRV\", \n        reader = reader, \n        outdir = \"./output\",  \n        label = \"HRV\", \n        dtype = \"float32\", \n        radius = 16000, \n        epsilon = .5, \n        nodata = -3.4E+38)\n\nNow we can read in the newly created file and take a look at a simple plot to visualize our result (Note that in the background, I am using R to generate this plot quickly).\n\nfile = \"output/MSG1-SEVI-MSG15-0100-NA-20160531090417.660000000Z-20160531090437-1405098_HRV.tif\"\nds = gdal.Open(file)\nband = ds.GetRasterBand(1)\ndata = band.ReadAsArray()\nplt.imshow(data)\n\n<matplotlib.image.AxesImage at 0x7f54fa1e1c90>"
  },
  {
    "objectID": "contents/blog/2020-06-21-docker.md/index.html",
    "href": "contents/blog/2020-06-21-docker.md/index.html",
    "title": "Running docker-compose with postgis and R-Studio",
    "section": "",
    "text": "What we need is a simple .yaml file that defines the parameters of our application. In the example I will demonstrate, the application consists of two services, namely the postigs server and the R-Studio instance. We start with the postgres service by defining which images we are using. This image is found at dockerhub If the images are not found on the local machine, they are pulled from there once we run our application. We also make the container’s naming explicit by using the container_name option and set the restart behavior to always in cases the container breaks down. We also ensure that the container will set up a new user besides the default postgres user by specifying a username and a password. The last part specifies on the left hand the local path on the host machine where the database files are going to be written two, while the right-hand part links to the data directory within the postgis container.\nservices:\n  postgres:\n  image: postgis/postgis\n  container_name: postgres\n  restart: always\n  environment:\n    POSTGRES_USER: postgis\n    POSTGRES_PASSWORD: postgis\n  ports:\n    - 8888:5432\n  volumes:\n    - ~/pgdata:/var/lib/postgresql/data\n\nrstudio:\n  image: rocker/geospatial\n  container_name: r-studio\n  restart: always\n  environment:\n    - USER=rstudio\n    - PASSWORD=supersecret\n    - ROOT=TRUE\n  ports:\n    - 8787:8787\n  links: \n    - postgres\nFor the R-Studio service, we use the geospatial image that comes in very handy in cases you want to do geospatial analysis since a large number of important packages already come preinstalled. We also make the naming of the container explicit and set the restart behavior to always. The rocker images are quite restrictive when it comes to user rights management. Thus, in addition to specifying a user and a password, we also want to enable root access for the case we need to install additional software. This way, our user is added to the sudoer list. However, this option should be treated carefully. We also map a port on the host machine to the exposed port of the container. This way, we can reach the interface by simply accessing http://localhost:8787/ in the browser of our choice. Finally, we declare that the posgres service is linked to the rstudio service. This means that inside the rstudio container, an entry to /etc/hosts called postgres is added, linking to the IP-address this container is found.\nWhen we write the above configuration to a file called docker-compose.yaml starting the application is as simple as running the following command in a shell in the same directory the file is found:\ndocker-compose up\nOnce the services are up and running, visit http://localhost:8787/ and enter the username and password for the rstudio service. From here, we can use the RPostgreSQL and RPostgres library to connect to our data base. In the simple example below, we establish a connection and write an sf-Object shipped with the sf package to the database.\nlibrary(RPostgreSQL)\nlibrary(RPostgres)\nlibrary(sf)\n\n# specify connection inputs\ndb <- 'postgis'  # provide the name of your db\nhost_db = \"postgres\" # provide the name of the service\ndb_port = '5432'  # specify the port the service is available at\ndb_user = \"postgis\"  # specify username\ndb_password = \"postgis\" # specify password\n# establish the connection\ncon <- dbConnect(Postgres(), \n                 dbname=db, \n                 host=host_db, \n                 port=db_port, \n                 user=db_user, \n                 password=db_password)\n\n# read sample shapefile\nshape = st_read(system.file(\"gpkg/nc.gpkg\", package = \"sf\"))\n# write to database in a new table specified by the layer argument\ntable_name = \"test\"\nst_write(obj = shape, dsn = con, layer = table_name)\nSince we mapped the data directory to a local directory on our host machine, the data we write into the database is persistent even when the application is no longer running. To query our database now or even after restarting the application we can use more sf functionality to interact with it. Here is a simple example comparing dplyr syntax with the result we obtain from querying the database to unify all polygons which have the same entry in the ‘SID74’ variable.\nlibrary(dplyr)\n\n# dplyr way of \nshape_dplyr = shape %>%\n  group_by(SID74) %>%\n  summarise(AREA = sum(AREA, na.rm = TRUE))\n\nshape_postgis = st_read(con, query = sprintf(paste0('SELECT \"SID74\", SUM(\"AREA\") as \"AREA\", ST_UNION(geom) as geom \\n',\n                                    'FROM \\\"%s\\\" \\n',\n                                    'GROUP BY \"SID74\";')), table_name)\nBut how can we manage our postgis server now? There are two ways (well, actually three ways I’ll explain in a minute) how we can access the server. The first one is using psql from the host machine. In the configuration file, we specified that the postgis containers port is mapped to the host machine’s port 8888. Well, we simply use that information to connect to the database using psql.\npsql --host localhost --port 8888 --dbname postgres --user postgis\nThe command line will ask us for the password, and then we are connected. Additionally, we can also choose to use a program with a graphical user interface to manage the data base. One which ich highly recommend is pgAdmin. After installing and running the program, we have to specify a new connection. After adding a name for the connection in the General tab we switch to the Connection tab and fill in all the information as in the screenshot below.\n\n\n\npgAdmin settings tab\n\n\nYou already guessed the third option I promised you before? Well of course we can use the psql approach explained above from the terminal in our R-Studio container. Of course, the hostname will be slightly different, but the basic idea is the same. Now, it comes in handy that we have root access in the R-Studio container, because we are going to need to install external software first, namely the postgres client. Thus we enter the following two lines into the terminal. Enter Yes in case you are asked if you wanted to install the software.\nsudo apt update\nsudo apt install postgresql-client\nNow our container has the psql command installed and we can use a slightly different version of the above command to connect to the databse.\npsql --host postgres --port 5432 --dbname postgres --user postgis\nWhat are the differences here? Well, first the container is not found at localhost but as explained before we have got an entry in the /etc/hosts file for our container name postgres. Additionally, we are connecting directly to the container and not to the mapped port on our host machine which is why we have to specify 5432 as the right port. Besides that, everything remains the same."
  },
  {
    "objectID": "contents/projects.html",
    "href": "contents/projects.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Tree species classification based on UAV orthoimages\n\n\n\n\n\n\n\nUAV\n\n\nRandomForest\n\n\nR\n\n\n\n\nExploration of tree species classification accuracy.\n\n\n\n\n\n\nApr 17, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nAerosol-Cloud Interactions and Precipitation in the Aral Sea basin\n\n\n\n\n\n\n\nMODIS\n\n\nClouds\n\n\nPrecipitaion\n\n\nR\n\n\n\n\nAnalysis of cloud-aersol interactions in the Aral Sea basin.\n\n\n\n\n\n\nJan 20, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nMachine Learning to classify microplastic particles\n\n\n\n\n\n\n\nMachine Learning\n\n\nMicroplastics\n\n\nCNN\n\n\nFTIR-Spectrometry\n\n\nR\n\n\n\n\nClassification of Fourier-Transform Spectra to classify microplastics.\n\n\n\n\n\n\nOct 22, 2019\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nLow-cost SensorBoxes for automated environmental monitoring\n\n\n\n\n\n\n\nEnvironment\n\n\nMonitoring\n\n\nRaspberry Pi\n\n\n\n\nLow-cost environmental sensor unit based on a Raspberry Pi 3.\n\n\n\n\n\n\nJul 20, 2019\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nForest stand analysis based on remote sensing\n\n\n\n\n\n\n\nMachine Learning\n\n\nLIDAR\n\n\nR\n\n\n\n\nA project using RGB images and LIDAR data to classify tree species and analyse forest stand structures.\n\n\n\n\n\n\nMay 31, 2019\n\n\nDarius A. Görgen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contents/projects/2019-07-01-sensorboxes/index.html",
    "href": "contents/projects/2019-07-01-sensorboxes/index.html",
    "title": "Low-cost SensorBoxes for automated environmental monitoring",
    "section": "",
    "text": "What is it about?\nThis project website documents a master’s seminar work at the University of Marburg on a fully automated, low-cost, and self-build environmental sensor unit used in the LOEWE research project Natur4.0. Its core part is a Raspberry Pi 3 (Model B) equipped with sensors to measure incoming radiation, temperature, and humidity, as well as a camera and a microphone to take records of animals in forest environments.\n\nCore Components\n\nRaspberry Pi 3 (B)\nRaspberry Pi Camera Module v2.1\nSF-555 Microphone (Foxnovo)\nDHT22-AM2302 Temperature and Humidity Sensor\nTSL2591 High Dynamic Range Digital Light Sensor\nKY-024 Hall Sensors\nDS3231 Real-Time Clock\nPowerBank and Wireless Charging Pads\n\n\n\n\nWhat it can do!\nThe SensorBox is a fully automated sensing unit that can be used in conjunction with a cable car mounted on specific trees to monitor environmental variables on a vertical gradient within forest structures. There is a need to regularly charge the batteries on the ground station and in case of the presence of a WLAN infrastructure, the SensorBox can send the collected data to another station. It can help to collect data on valuable parameters which can be used together with remotely sensed imagery, e.g., by UAVs, to predict the spatial distribution of these parameters below the canopy cover.\n\nCheck it out here or follow the link to GitHub to explore the source code of the website. Note that the content shown here comes from a student project and only covers the status during our two-week seminar. Check out the official documentation for more recent information."
  },
  {
    "objectID": "contents/projects/2019-10-15-polymeRID/index.html",
    "href": "contents/projects/2019-10-15-polymeRID/index.html",
    "title": "Machine Learning to classify microplastic particles",
    "section": "",
    "text": "What is it about?\nMicroplastic particles in the environment are an ever-growing concern in public and science. It is suspected not only to pose threats to wildlife but also concerns for human health have been raised. Scientists and especially decision-makers depend on the availability of precise and timely information on the where and when’s of microplastic in the environment. However, the process of spectral identification of particles remains a cost-intensive process requiring humans to invest time and effort into the correct identification of spectra. Modern machine learning techniques have the potential to decrease the necessity of human intervention in the classification process and thus significantly speed up the complete process from taking environmental samples to communicate the results to the public.\n\n\nWhat it can do!\nBased on a freely available reference data base published by Primpke and colleagues I developed a decision fusion algorithm based on two Random Forest models and two Convolutional Neural Networks which together can robustly identify polymers based on FTIR-spectral data. The complete workflow is reproducible and adjustable and consists of the following stages: preparation of a reference data base, exploration of machine learning models and pre-processing techniques, calibration of the final decision fusion algorithm, and classification of real-world spectral samples. The algorithm was written in R and the code is available on a GitHub repository. Additionally, there is a workflowr website communicating the structure of the algorithm and the results based on the mentioned OpenSource data base.\n\nHere you can explore the spectral reference data base based on selected polymers and other materials commonly found in environmental samples. Simply choose a class you wish to display and explore its spectral characteristics."
  },
  {
    "objectID": "contents/projects/2020-03-20-aciASB/index.html",
    "href": "contents/projects/2020-03-20-aciASB/index.html",
    "title": "Aerosol-Cloud Interactions and Precipitation in the Aral Sea basin",
    "section": "",
    "text": "What it can do!\nThe mechanisms which govern the cloud-aerosol interactions mainly depend on the type of aerosol, whether it acts hydrophilic or hydrophobic, and its size. Some mechanisms are expected to suppress precipitation, while others are suspected of leading to more severe and intense precipitation events. To investigate the relationship between aerosols and precipitation, I made use of the MODIS cloud and aerosol products as well as the CHIRPS data set.\nThe former uses satellite and ground observations to retrieve rainfall rates at a monthly resolution. The cloud and aerosol parameters were aggregated to the same spatial and temporal resolution to allow a correlation analysis.\n\n\n\n\nCorrelation AOD and P\n\n\nDuring spring (a) and winter (d), a negative relationship between the Aerosol Optical Depth (AOD) and precipitation rates (P) govern the study area. During the other two seasons, we also see pixels with positive correlations. However, these are not significant (pixels with a significant correlation are marked by crosses). The analysis was done in R and included data from 2003 to 2018 because since then, both MODIS satellites delivered observations for the study area. The source code of the complete project can be found in a GitHub repository, along with a more comprehensive discussion of the results."
  },
  {
    "objectID": "contents/projects/2019-05-31-mof/index.html",
    "href": "contents/projects/2019-05-31-mof/index.html",
    "title": "Forest stand analysis based on remote sensing",
    "section": "",
    "text": "Tree species biodiversity map.\n\nWhat is it about?\nForests represent the most diverse habitat for different species around the globe. Their monitoring is one of the most crucial tasks for biodiversity management. Traditional means of monitoring forests are cost and labor-intensive, which leads to low revisit frequencies and small monitored areas. Additionally, the results of data acquisitions by human agents make the results hardly reproducible. To overcome these limitations, a LOEWE research project called Natur4.0 has been initiated between several German research institutes. In this project, I participated in a student’s seminar and analyzed tree species and forest structures employing remote sensing techniques.\n\n\nWhat it can do!\nIn this project, I used RGB orthoimages and a point cloud derived from Light Detection and Ranging (LiDAR) data to train a segmentation algorithm to distinguish between individual trees based on a Canopy Height Model. This technique is based on a watershed algorithm that “grows” continues segments around a tree’s central position to delineate the total tree crown.\n\n\n\nAnimation of the tree segmentation\n\n\nOnce we successfully generated the tree objects, we used an object-based classification of the tree species. As predictors, we used several artificially created indices and filters from RGB images. Finally, we trained a Random Forest model to predict the tree species. Using the point cloud, structural forest parameters, such as vegetation density, can be aggregated on the level of individual trees and then analyzed. We see this result in the picture above where I calculated the Shannon-Index based on the number of different tree species found in a circular 10 meters environment. Green colors show lower numbers of tree species, while red colors indicate a relative species richness.\n\nYou can check out the results on a comprehensive website! You are also invited to read through the code for the analysis."
  },
  {
    "objectID": "contents/projects/2020-04-17-pheno/index.html",
    "href": "contents/projects/2020-04-17-pheno/index.html",
    "title": "Tree species classification based on UAV orthoimages",
    "section": "",
    "text": "What is it about?\nSupervised machine learning algorithms can help to extract useful information from high-dimensional datasets to benefit environmental conversation efforts. The correct identification of tree species based on imagery collected by low-cost UAVs and conventional cameras is undoubtedly a promising advancement in technology which might reduce the cost of local forest monitoring. Because the broader use of this technology only occurred very recently, structural investigations into the benefits and the limitations of this approach are limited. As a student’s team, we set out to investigate the relationship between the classification accuracy and different spatial resolutions of the imagery. Additionally, we were interested in the question of whether or not predictor variables calculated based on multi-temporal observations throughout the growing season enhances the classification.\n\n\nWhat can it do?\nWe established an empirical experiment to investigate the influence of spatial resolution and mono- vs. multi-temporal predictor variables using the Random Forest algorithm. We used 5-fold cross-validation combined with the Leave-Location-Out approach (LLOCV) to train a total number of 9 models. These included each combination of three different spatial resolutions (10, 15, and 25 cm) and three different combinations of the predictor variables (mono-temporal, seasonal, and both predictor sets.)\n\n\n\nAccuracies of a 5-fold cross-validation\n\n\nWe learned that a medium resolutions seems beneficial and that seasonal parameters are able to increase the classification accuracy at about 1-2 %. There were also indications, that object-based classification has the potential to significantly increase the overall accuracy.\n\nInterested in the results? Check out our written report or browse through our R code workflow."
  },
  {
    "objectID": "contents/blog.html",
    "href": "contents/blog.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "R API to download FAO’s WaPOR datasets\n\n\n\n\n\n\n\nR\n\n\nraster\n\n\nFAO WAPOR\n\n\nAPI\n\n\n\n\nA R API package to query and download FAO’s WaPOR raster datasets.\n\n\n\n\n\n\nOct 31, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nRunning docker-compose with postgis and R-Studio\n\n\n\n\n\n\n\nR\n\n\ndocker\n\n\nPostgreSQL\n\n\n\n\nUsing docker-compose to set up a R-Studio container and postgis.\n\n\n\n\n\n\nJun 21, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nTranslating EUMETSAT’s .nat files to GTiff\n\n\n\n\n\n\n\nMSG\n\n\nGTIFF\n\n\nPython\n\n\n\n\nPython code to translate EUMETSAT’s .nat datasets to GTiffs.\n\n\n\n\n\n\nMay 10, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\n  \n\n\n\n\nTranslating EUMETSAT’s .bfr files to GTiff\n\n\n\n\n\n\n\nBUFR\n\n\nTIFF\n\n\nPython\n\n\n\n\nPython code to translate EUMETSAT’s BUFR datasets to GTiffs.\n\n\n\n\n\n\nMay 1, 2020\n\n\nDarius A. Görgen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "I am anworking on a range of topics concerned with environmental change and the associated coping strategies of our societies. I have been studying Geography and Political Sciences of the MENA region at the University of Marburg, focusing on Remote Sensing, Climatology, and Hydrogeography. In my projects I apply my Data Science skills to help teams to generate information for better decision making. Currently, I am working as a research associate at the Federal Institute for Geosciences and Resources. I also offer freelance consulting services using R and Python for reproducible analysis of spatial data.\n\n\n\nR\nR Markdown\nQuarto\nPython\nShiny\nDocker\nData Analysis\nMachine Learning\nGeographic Information System\nPostgreSQL\nBash\n\n\n\n\nContributor to the MAPME Initiative: Maps for Planning, Monitoring, and Evaluation in the Development Cooperation Sector, funded by KfW, www.mapme-initiative.org\nmapme.biodiversity: Maintainer of an R package for the collection of variables for global biodiversity portfolios.\nM.Sc. thesis on Predicting violent conflict in Africa - Leveraging open geodata and deep learning for spatiotemporal event detection https://goergen95.github.io/thesis-predicting-conflict"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/idna-3.3.dist-info/LICENSE.html",
    "href": "py-env/lib/python3.10/site-packages/idna-3.3.dist-info/LICENSE.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Copyright (c) 2013-2021, Kim Davies All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "href": "py-env/lib/python3.10/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/satpy-0.37.1.dist-info/AUTHORS.html",
    "href": "py-env/lib/python3.10/site-packages/satpy-0.37.1.dist-info/AUTHORS.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "The following people have made contributions to this project:\n\n\n\n\n\nTrygve Aspenes (TAlonglong)\nTalfan Barnie (TalfanBarnie)\nJonathan Beavers (jon4than)\nSuyash Behera (Suyash458)\nRay Bell (raybellwaves)\nJorge Bravo (jhbravo)\nSebastian Brodehl (sbrodehl)\nAndrew Brooks (howff)\nGuido della Bruna - meteoswiss\nPierre de Buyl (pdebuyl)\nEric Bruning (deeplycloudy)\nLorenzo Clementi (loreclem)\nColin Duff (ColinDuff)\nRadar, Satellite and Nowcasting Division (meteoswiss-mdr)\nRohan Daruwala (rdaruwala)\nAdam Dybbroe (adybbroe)\nUlrik Egede (egede)\nJoleen Feltz (joleenf)\nStephan Finkensieper (sfinkens) - Deutscher Wetterdienst\nAndrea Grillini (AppLEaDaY)\nBlanka Gvozdikova (gvozdikb)\nNina Håkansson (ninahakansson)\nUlrich Hamann\nMitch Herbertson (mherbertson)\nGerrit Holl (gerritholl) - Deutscher Wetterdienst\nDavid Hoese (djhoese)\nMarc Honnorat (honnorat)\nMikhail Itkin (mitkin)\nTommy Jasmin (tommyjasmin)\nJactry Zeng\nJohannes Johansson (JohannesSMHI)\nSauli Joro (sjoro)\nJanne Kotro (jkotro)\nRalph Kuehn (ralphk11)\nPanu Lahtinen (pnuu)\nJussi Leinonen (jleinonen) - meteoswiss\nThomas Leppelt (m4sth0) - Deutscher Wetterdienst\nLu Liu (yukaribbba)\nAndrea Meraner (ameraner)\nAronne Merrelli (aronnem)\nLucas Meyer (LTMeyer)\nOndrej Nedelcev (nedelceo)\nOana Nicola\nEsben S. Nielsen (storpipfugl)\nTom Parker (tparker-usgs)\nChristian Peters (peters77)\nPepe Phillips (pepephillips)\nGhislain Picard (ghislainp)\nSimon R. Proud (simonrp84)\nLars Ørum Rasmussen (loerum)\nMartin Raspaud (mraspaud)\nWilliam Roberts (wroberts4)\nPascale Roquet (roquetp)\nKristian Rune Larsen\nRutgerK (RutgerK)\nMarco Sassi - meteoswiss\nStefan Scheiblauer (StefanSnippetCoder)\nRonald Scheirer\nHauke Schulz (observingClouds)\nJakub Seidl (seidlj)\nEysteinn Sigurðsson (eysteinn)\nJean-Luc Shaw (jeanlucshaw)\nDario Stelitano (bornagain1981)\nJohan Strandgren (strandgren)\nMatias Takala (elfsprite)\nTaiga Tsukada (tsukada-cs)\nChristian Versloot (christianversloot)\nHelga Weber (helgaweb)\nhazbottles (hazbottles)\noananicola (oananicola)\npraerien (praerien)\nXin Zhang (zxdawn)\nYufei Zhu (yufeizhu600)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/QtPy-2.2.0.dist-info/AUTHORS.html",
    "href": "py-env/lib/python3.10/site-packages/QtPy-2.2.0.dist-info/AUTHORS.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "href": "py-env/lib/python3.10/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "href": "py-env/lib/python3.10/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "Darius A. Görgen",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figues embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "py-env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "Darius A. Görgen",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "href": "py-env/lib/python3.10/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "href": "py-env/lib/python3.10/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "John Jacobsen @eigenhombre\nErik Welch @eriknw\nJohn Crichton @jcrichton\nHan Semaj @microamp\nGraeme Coupar @obmarg\nLeonid Shvechikov @shvechikov\nLars Buitinck @larsmans\nJosé Ricardo @josericardo\nTom Prince @tomprince\nBart van Merriënboer @bartvm\nNikolaos-Digenis Karagiannis @digenis\nAntonio Lima @themiurgo\nJoe Jevnik @llllllllll\nRory Kirchner @roryk\nSteven Cutting @steven_cutting\nAric Coady @coady"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbformat-5.4.0.dist-info/COPYING.html",
    "href": "py-env/lib/python3.10/site-packages/nbformat-5.4.0.dist-info/COPYING.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "href": "py-env/lib/python3.10/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Copyright (c) 2018 - 2022 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "py-env/lib/python3.10/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Autokill.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Autokill.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "import os\nimport signal\npid = os.getpid()\nos.kill(pid, signal.SIGTERM)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Sleep1s.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Sleep1s.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "t0 = datetime.datetime.utcnow()\ntime.sleep(1)\nt1 = datetime.datetime.utcnow()\n\n\ntime_format = '%Y-%m-%dT%H:%M:%S.%fZ'\nprint(t0.strftime(time_format), end='')\n\n\nprint(t1.strftime(time_format), end='')"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'A'\nother_notebook = 'B'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/update-display-id.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/update-display-id.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "display('above')\ndisplay_with_id(1, 'here')\ndisplay('below')\n\n'above'\n\n\n8\n\n\n'below'\n\n\n\ndisplay_with_id(2, 'here')\ndisplay_with_id(3, 'there')\ndisplay_with_id(4, 'here')\n\n8\n\n\n6\n\n\n8\n\n\n\ndisplay_with_id(5, 'there')\ndisplay_with_id(6, 'there', update=True)\n\n6\n\n\n\ndisplay_with_id(7, 'here')\ndisplay_with_id(8, 'here', update=True)\ndisplay_with_id(9, 'result', execute_result=True)\n\n8\n\n\n10\n\n\n\ndisplay_with_id(10, 'result', update=True)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Unicode.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Unicode.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Clear Output.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Clear Output.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "for i in range(10):\n    clear_output()\n    print(i)\n\n9\n\n\n\nprint(\"Hello world\")\nclear_output()\n\n\nprint(\"Hello world\", end='')\nclear_output(wait=True)  # no output after this\n\nHello world\n\n\n\nprint(\"Hello\", end='')\nclear_output(wait=True)  # here we have new output after wait=True\nprint(\"world\", end='')\n\nworld\n\n\n\nhandle0 = display(\"Hello world\", display_id=\"id0\")\n\n'Hello world'\n\n\n\nhandle1 = display(\"Hello\", display_id=\"id1\")\n\n'world'\n\n\n\nhandle1.update('world')\n\n\nhandle2 = display(\"Hello world\", display_id=\"id2\")\nclear_output()  # clears all output, also with display_ids\n\n\nhandle3 = display(\"Hello world\", display_id=\"id3\")\nclear_output(wait=True)\n\n'Hello world'\n\n\n\nhandle4 = display(\"Hello\", display_id=\"id4\")\nclear_output(wait=True)\nprint('world', end='')\n\nworld\n\n\n\nhandle4.update('Hello world')  # it is cleared, so it should not show up in the above cell"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Other Comms.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Other Comms.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "comm = Comm('this-comm-tests-a-missing-handler', data={'id': 'foo'})\n\n\ncomm.send(data={'id': 'bar'})"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Empty Cell.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Empty Cell.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "\"Code 1\"\n\n'Code 1'\n\n\n\n\"Code 2\"\n\n'Code 2'"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Factorials.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Factorials.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "for m in range(10):\n    i, j = j, i + j\n    print(j)\n\n2\n3\n5\n8\n13\n21\n34\n55\n89\n144"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'B'\nother_notebook = 'A'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/UnicodePy3.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/UnicodePy3.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Error.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Error.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "0/0\n\nZeroDivisionError: division by zero"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Check History in Memory.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Check History in Memory.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "ip = get_ipython()\nassert ip.history_manager.hist_file == ':memory:'"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "# it should also handle custom msg'es\nlabel.send({'msg': 'Hello'})"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Output.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Output.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print(\"hi\")\nwith output1:\n    print(\"in output\")\n\nhi\n\n\n\nwith output1:\n    raise ValueError(\"trigger msg_type=error\")\n\n\nimport ipywidgets as widgets\noutput2 = widgets.Output()\noutput2\n\n\n\n\n\nprint(\"hi2\")\nwith output2:\n    print(\"in output2\")\n    clear_output(wait=True)\n\nhi2\n\n\n\nimport ipywidgets as widgets\noutput3 = widgets.Output()\noutput3\n\n\n\n\n\nprint(\"hi3\")\nwith output3:\n    print(\"hello\")\n    clear_output(wait=True)\n    print(\"world\")\n\nhi3\n\n\n\nimport ipywidgets as widgets\noutput4 = widgets.Output()\noutput4\n\n\n\n\n\nprint(\"hi4\")\nwith output4:\n    print(\"hello world\")\n    clear_output()\n\nhi4\n\n\n\nimport ipywidgets as widgets\noutput5 = widgets.Output()\noutput5\n\n\n\n\n\nprint(\"hi5\")\nwith output5:\n    display(\"hello world\") # this is not a stream but plain text\nclear_output()\n\n\nimport ipywidgets as widgets\noutput_outer = widgets.Output()\noutput_inner = widgets.Output()\noutput_inner\n\n\n\n\n\noutput_outer\n\n\n\n\n\nwith output_inner:\n    print('in inner')\n    with output_outer:\n        print('in outer')\n    print('also in inner')"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Disable Stdin.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Disable Stdin.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "try:\n    input = raw_input\nexcept:\n    pass\n\nname = input(\"name: \")"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Interrupt.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Interrupt.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print(\"done\")\n\ndone"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Inline Image.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Inline Image.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "Image('python.png')"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/SVG.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/SVG.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "SVG(data='''\n<svg height=\"100\" width=\"100\">\n    <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n</svg>''')"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "py-env/lib/python3.10/site-packages/nbclient/tests/files/HelloWorld.html",
    "href": "py-env/lib/python3.10/site-packages/nbclient/tests/files/HelloWorld.html",
    "title": "Darius A. Görgen",
    "section": "",
    "text": "print(\"Hello World\")\n\nHello World"
  }
]
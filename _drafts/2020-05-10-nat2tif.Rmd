---
output:
 html_document:
   keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, python.reticulate = reticulate::eng_python)
library(reticulate)
use_condaenv("bufr2netcdf")
```


In this tutorial I am using Python to translate an Meteosat Second Generation (MSG) Native Archive Format (.nat) file to GTiff. Conveniently, there exist a
driver support for these files in both, the [gdal](https://gdal.org/drivers/raster/msgn.html) 
and the [satpy](https://satpy.readthedocs.io/en/latest/index.html) library.
Here, we are going to use satpy because we also want to resample the data
with its "associated" library [pyresample](https://pyresample.readthedocs.io/en/latest/). First we will load
all the libraries we are going to need into our Python session.

```{python libs}
import numpy as np
import gdal
import osr
import os
import pyresample as pr
from satpy import Scene
```

Opposed to BUFR files, for which currently now drivers are available,
reading _.nat_ files is actually quite straight forward. All we need to do is 
handing the right reader to the satpy _Scene_ function. We can then take a look
at the available datasets.

```{python parameters}
file = "../assets/files/MSG1-SEVI-MSG15-0100-NA-20160531090417.660000000Z-20160531090437-1405098.nat"
# define reader
reader = "seviri_l1b_native"
# read the file
scn = Scene(filenames = {reader:[file]})
# extract data set names
dataset_names = scn.all_dataset_names()
# print available datasets
print('\n'.join(map(str, dataset_names)))
```
The MSG data is provided as Full Disk, meaning that roughly the complete North-South
extent of the globe from the Atlantic to the Indian Ocean is present in 
each file. For most applications and research questions it is not really necessary
to process an extent that large. Which is why as an example we are going to resample
the data to the extent of Spain. For this to work we are using functionality 
from the _pyresample_ library, which allows user to create customized area definitions.

```{python}
# create some information on the reference system
area_id = "Spain"
description = "Geographical Coordinate System clipped on Spain"
proj_id = "Spain"
# specifing some parameters of the projection
proj_dict = {"proj": "longlat", "ellps": "WGS84", "datum": "WGS84"}
# calculate the width and height of the aoi in pixels
llx = -9.5 # lower left x coordinate in degrees
lly = 35.9 # lower left y coordinate in degrees
urx = 3.3 # upper right x coordinate in degrees
ury = 43.8 # upper right y coordinate in degrees
resolution = 0.005 # target resolution in degrees
# calculating the number of pixels
width = int((urx - llx) / resolution)
height = int((ury - lly) / resolution)
area_extent = (llx,lly,urx,ury)
# defining the area
area_def = pr.geometry.AreaDefinition(area_id, proj_id, description, proj_dict, width, height, area_extent)
print(area_def)
```
What we are going to show here, is how to proceed when we want to extract more
than one specific data set. For this to work we can either apply a for loop
over the desired datasets we need of we write a general function which is able 
to extract the data for any specified variable. Here we are going forward with
the latter approach because most of the time a function more reusable than a 
simple script.

```{python data}
def nat2tif(file, calibration, area_def, dataset, reader, outdir, label, dtype, radius, epsilon, nodata):
  # open the file
  scn = Scene(filenames = {reader: [file]})
  # let us check that the specified data set is actually available
  scn_names = scn.all_dataset_names()
  # raise exception if dataset is not present in available names
  if dataset not in scn_names:
    raise Exception("Specified dataset is not available.")
  # we need to load the data, different calibration can be chosen
  scn.load([dataset], calibration=calibration)
  # let us extract the longitude and latitude data
  lons, lats = scn[dataset].area.get_lonlats()
  # now we can apply a swath definition for our output raster
  swath_def = pr.geometry.SwathDefinition(lons=lons, lats=lats)
  # and finally we also extract the data
  values = scn[dataset].values
  # we will now change the datatype of the arrays
  # depending on the present data this can be changed
  lons = lons.astype(dtype)
  lats = lats.astype(dtype)
  values = values.astype(dtype)
  # now we can already resample our data to the area of interest
  values = pr.kd_tree.resample_nearest(swath_def, values,
                                             area_def,
                                             radius_of_influence=radius, # in meters
                                             epsilon=epsilon,
                                             fill_value=False)
  # we are going to check if the outdir exists and create it if it doesnt
  if not os.path.exists(outdir):
   os.makedir(outdir)
  # let us join our filename based on the input file's basename                                           
  outname = os.path.join(outdir, os.path.basename(file)[:-4] + "_" + str(label) + ".tif")
  # now we define some metadata for our raster file
  cols = values.shape[1]
  rows = values.shape[0]
  pixelWidth = (area_def.area_extent[2] - area_def.area_extent[0]) / cols
  pixelHeight = (area_def.area_extent[1] - area_def.area_extent[3]) / rows
  originX = area_def.area_extent[0]
  originY = area_def.area_extent[3] 
  # here we actually create the file
  driver = gdal.GetDriverByName("GTiff")
  outRaster = driver.Create(outname, cols, rows, 1)
  # writing the metadata
  outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
  # creating a new band and writting the data
  outband = outRaster.GetRasterBand(1)
  outband.SetNoDataValue(nodata) #specified no data value by user
  outband.WriteArray(np.array(values)) # writting the values
  outRasterSRS = osr.SpatialReference() # create CRS instance
  outRasterSRS.ImportFromEPSG(4326) # get info for EPSG 4326
  outRaster.SetProjection(outRasterSRS.ExportToWkt()) # set CRS as WKT
  # clean up
  outband.FlushCache()
  outband = None
  outRaster = None
  
```

Now we can apply this function to our input file and extract any dataset which
is available. Note that some of the input variables need further explanation.
The very first option which might not be self-evident is calibration. With this 
option we can tell satpy to pre-calibrate the data for example to reflectance in
contrast to radiances. The option _label_ appends the value of label to the 
ouput filename. With the _dtype_ option we can specifically chose which datatype
is used for the ouput file. Accordingly, we should adapt the value for nodata,
which is used to flag no data values in the output file.
The options _radius_ and _epsilon_ are options of the neireghst neihbour resampling
routine and can be specified to the user needs (see [here](https://pyresample.readthedocs.io/en/latest/swath.html#pyresample-kd-tree) for more information).

```{python, show = F}
nat2tif(file = file, 
        calibration = "radiance",  
        area_def = area_def,  
        dataset = "HRV", 
        reader = reader, 
        outdir = "../assets/files",  
        label = "HRV", 
        dtype = "float32", 
        radius = 16000, 
        epsilon = .5, 
        nodata = -3.4E+38)
```
Now we can read in the newly created file and take a look at a simple plot
to visualize our result (Note that in the background I am using R to quickly generate
this plot).

```{r plot, echo = F, warning=F, message=F}
library(raster)
library(rnaturalearth)
r = raster(list.files("../assets/files", "HRV", full.names = T))
names(r) = "HRV"
cnt = ne_countries()
cnt = crop(cnt, r)
plot(r, col = grey(1:250/250))
plot(cnt, add =T, border = "red")
```


